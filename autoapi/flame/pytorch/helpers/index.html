
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>flame.pytorch.helpers &#8212; flame 0.0.1 documentation</title>
    
  <link href="../../../../_static/css/theme.css" rel="stylesheet" />
  <link href="../../../../_static/css/index.f6b7ca918bee2f46fd9abac01cfb07d5.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/graphviz.css" />
    
  <link rel="preload" as="script" href="../../../../_static/js/index.1e043a052b0af929e4d8.js">

    <script id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
    <script src="../../../../_static/jquery.js"></script>
    <script src="../../../../_static/underscore.js"></script>
    <script src="../../../../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
    <link rel="next" title="flame.pytorch.helpers.amp" href="amp/index.html" />
    <link rel="prev" title="flame.pytorch" href="../index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">


    
    <a class="navbar-brand" href="../../../../index.html">
      <p class="title">flame</p>
    </a>
    

    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    
    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        <li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="../../../index.html">
  API Reference
 </a>
</li>

        
      </ul>

      <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l2 current active">
  <a class="reference internal" href="../../index.html">
   <code class="xref py py-mod docutils literal notranslate">
    <span class="pre">
     flame
    </span>
   </code>
  </a>
  <ul class="current">
   <li class="toctree-l3">
    <a class="reference internal" href="../../core/index.html">
     <code class="xref py py-mod docutils literal notranslate">
      <span class="pre">
       flame.core
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l3">
    <a class="reference internal" href="../../oneflow/index.html">
     <code class="xref py py-mod docutils literal notranslate">
      <span class="pre">
       flame.oneflow
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l3 current active">
    <a class="reference internal" href="../index.html">
     <code class="xref py py-mod docutils literal notranslate">
      <span class="pre">
       flame.pytorch
      </span>
     </code>
    </a>
    <ul class="current">
     <li class="toctree-l4 current active">
      <a class="current reference internal" href="#">
       <code class="xref py py-mod docutils literal notranslate">
        <span class="pre">
         flame.pytorch.helpers
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l4">
      <a class="reference internal" href="../meters/index.html">
       <code class="xref py py-mod docutils literal notranslate">
        <span class="pre">
         flame.pytorch.meters
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l4">
      <a class="reference internal" href="../metrics/index.html">
       <code class="xref py py-mod docutils literal notranslate">
        <span class="pre">
         flame.pytorch.metrics
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l4">
      <a class="reference internal" href="../nn/index.html">
       <code class="xref py py-mod docutils literal notranslate">
        <span class="pre">
         flame.pytorch.nn
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l4">
      <a class="reference internal" href="../trainer/index.html">
       <code class="xref py py-mod docutils literal notranslate">
        <span class="pre">
         flame.pytorch.trainer
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l4">
      <a class="reference internal" href="../utils/index.html">
       <code class="xref py py-mod docutils literal notranslate">
        <span class="pre">
         flame.pytorch.utils
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l4">
      <a class="reference internal" href="../arguments/index.html">
       <code class="xref py py-mod docutils literal notranslate">
        <span class="pre">
         flame.pytorch.arguments
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l4">
      <a class="reference internal" href="../container/index.html">
       <code class="xref py py-mod docutils literal notranslate">
        <span class="pre">
         flame.pytorch.container
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l4">
      <a class="reference internal" href="../distributed/index.html">
       <code class="xref py py-mod docutils literal notranslate">
        <span class="pre">
         flame.pytorch.distributed
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l4">
      <a class="reference internal" href="../engine/index.html">
       <code class="xref py py-mod docutils literal notranslate">
        <span class="pre">
         flame.pytorch.engine
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l4">
      <a class="reference internal" href="../experiment/index.html">
       <code class="xref py py-mod docutils literal notranslate">
        <span class="pre">
         flame.pytorch.experiment
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l4">
      <a class="reference internal" href="../launcher/index.html">
       <code class="xref py py-mod docutils literal notranslate">
        <span class="pre">
         flame.pytorch.launcher
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l4">
      <a class="reference internal" href="../sampler/index.html">
       <code class="xref py py-mod docutils literal notranslate">
        <span class="pre">
         flame.pytorch.sampler
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l4">
      <a class="reference internal" href="../typing_prelude/index.html">
       <code class="xref py py-mod docutils literal notranslate">
        <span class="pre">
         flame.pytorch.typing_prelude
        </span>
       </code>
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l3">
    <a class="reference internal" href="../../__main__/index.html">
     <code class="xref py py-mod docutils literal notranslate">
      <span class="pre">
       flame.__main__
      </span>
     </code>
    </a>
   </li>
  </ul>
 </li>
</ul>
  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#submodules">
   Submodules
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#package-contents">
   Package Contents
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#functions">
     Functions
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#flame.pytorch.helpers.create_data_loader">
       create_data_loader
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#flame.pytorch.helpers.create_ddp_model">
       create_ddp_model
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#flame.pytorch.helpers.cudnn_benchmark_if_possible">
       cudnn_benchmark_if_possible
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#flame.pytorch.helpers.scale_lr_linearly">
       scale_lr_linearly
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#flame.pytorch.helpers.num_valid_samples_from_data_loader">
       num_valid_samples_from_data_loader
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#flame.pytorch.helpers.save_checkpoint">
       save_checkpoint
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#flame.pytorch.helpers.rank0">
       rank0
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

</nav>


              
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="section" id="module-flame.pytorch.helpers">
<span id="flame-pytorch-helpers"></span><h1><a class="reference internal" href="#module-flame.pytorch.helpers" title="flame.pytorch.helpers"><code class="xref py py-mod docutils literal notranslate"><span class="pre">flame.pytorch.helpers</span></code></a><a class="headerlink" href="#module-flame.pytorch.helpers" title="Permalink to this headline">¶</a></h1>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="amp/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">flame.pytorch.helpers.amp</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="checkpoint_saver/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">flame.pytorch.helpers.checkpoint_saver</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="cudnn/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">flame.pytorch.helpers.cudnn</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="data/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">flame.pytorch.helpers.data</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="model/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">flame.pytorch.helpers.model</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="optimizer/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">flame.pytorch.helpers.optimizer</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="tensorboard/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">flame.pytorch.helpers.tensorboard</span></code></a></li>
</ul>
</div>
</div>
<div class="section" id="package-contents">
<h2>Package Contents<a class="headerlink" href="#package-contents" title="Permalink to this headline">¶</a></h2>
<div class="section" id="functions">
<h3>Functions<a class="headerlink" href="#functions" title="Permalink to this headline">¶</a></h3>
<table class="longtable table autosummary">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#flame.pytorch.helpers.create_data_loader" title="flame.pytorch.helpers.create_data_loader"><code class="xref py py-obj docutils literal notranslate"><span class="pre">create_data_loader</span></code></a>(dataset, batch_size = 1, shuffle = True, num_workers = 0, collate_fn=None, pin_memory = True, multiprocessing_context=None, persistent_workers = True, drop_last = False, worker_init_fn = None)</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#flame.pytorch.helpers.create_ddp_model" title="flame.pytorch.helpers.create_ddp_model"><code class="xref py py-obj docutils literal notranslate"><span class="pre">create_ddp_model</span></code></a>(base_model, device, use_sync_bn = False, find_unused_parameters = False)</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#flame.pytorch.helpers.cudnn_benchmark_if_possible" title="flame.pytorch.helpers.cudnn_benchmark_if_possible"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cudnn_benchmark_if_possible</span></code></a>()</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#flame.pytorch.helpers.scale_lr_linearly" title="flame.pytorch.helpers.scale_lr_linearly"><code class="xref py py-obj docutils literal notranslate"><span class="pre">scale_lr_linearly</span></code></a>(base_lr, batch_size, world_size = None, base_batch_size = 256)</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#flame.pytorch.helpers.num_valid_samples_from_data_loader" title="flame.pytorch.helpers.num_valid_samples_from_data_loader"><code class="xref py py-obj docutils literal notranslate"><span class="pre">num_valid_samples_from_data_loader</span></code></a>(loader)</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#flame.pytorch.helpers.save_checkpoint" title="flame.pytorch.helpers.save_checkpoint"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save_checkpoint</span></code></a>(state, experiment_dir, is_best = False, filename='checkpoint.pth.tar')</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#flame.pytorch.helpers.rank0" title="flame.pytorch.helpers.rank0"><code class="xref py py-obj docutils literal notranslate"><span class="pre">rank0</span></code></a>(func)</p></td>
<td><p>run func only on rank 0</p></td>
</tr>
</tbody>
</table>
<dl class="py function">
<dt id="flame.pytorch.helpers.create_data_loader">
<code class="sig-prename descclassname"><span class="pre">flame.pytorch.helpers.</span></code><code class="sig-name descname"><span class="pre">create_data_loader</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shuffle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_workers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">collate_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pin_memory</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">multiprocessing_context</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">persistent_workers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">drop_last</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">worker_init_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#flame.pytorch.helpers.create_data_loader" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dataset</strong> (<em>torch.utils.data.Dataset</em>) – </p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – </p></li>
<li><p><strong>shuffle</strong> (<em>bool</em>) – </p></li>
<li><p><strong>num_workers</strong> (<em>int</em>) – </p></li>
<li><p><strong>pin_memory</strong> (<em>bool</em>) – </p></li>
<li><p><strong>persistent_workers</strong> (<em>bool</em>) – </p></li>
<li><p><strong>drop_last</strong> (<em>bool</em>) – </p></li>
<li><p><strong>worker_init_fn</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>int</em><em>]</em><em>, </em><em>None</em><em>]</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>torch.utils.data.DataLoader</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="flame.pytorch.helpers.create_ddp_model">
<code class="sig-prename descclassname"><span class="pre">flame.pytorch.helpers.</span></code><code class="sig-name descname"><span class="pre">create_ddp_model</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">base_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_sync_bn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">find_unused_parameters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#flame.pytorch.helpers.create_ddp_model" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>base_model</strong> (<em>torch.nn.Module</em>) – </p></li>
<li><p><strong>device</strong> (<em>torch.device</em>) – </p></li>
<li><p><strong>use_sync_bn</strong> (<em>bool</em>) – </p></li>
<li><p><strong>find_unused_parameters</strong> (<em>bool</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>torch.nn.Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="flame.pytorch.helpers.cudnn_benchmark_if_possible">
<code class="sig-prename descclassname"><span class="pre">flame.pytorch.helpers.</span></code><code class="sig-name descname"><span class="pre">cudnn_benchmark_if_possible</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#flame.pytorch.helpers.cudnn_benchmark_if_possible" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="flame.pytorch.helpers.scale_lr_linearly">
<code class="sig-prename descclassname"><span class="pre">flame.pytorch.helpers.</span></code><code class="sig-name descname"><span class="pre">scale_lr_linearly</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">base_lr</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">world_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">256</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#flame.pytorch.helpers.scale_lr_linearly" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>base_lr</strong> (<em>float</em>) – </p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – </p></li>
<li><p><strong>world_size</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – </p></li>
<li><p><strong>base_batch_size</strong> (<em>int</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="flame.pytorch.helpers.num_valid_samples_from_data_loader">
<code class="sig-prename descclassname"><span class="pre">flame.pytorch.helpers.</span></code><code class="sig-name descname"><span class="pre">num_valid_samples_from_data_loader</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">loader</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#flame.pytorch.helpers.num_valid_samples_from_data_loader" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>loader</strong> (<em>torch.utils.data.dataloader.DataLoader</em>) – </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="flame.pytorch.helpers.save_checkpoint">
<code class="sig-prename descclassname"><span class="pre">flame.pytorch.helpers.</span></code><code class="sig-name descname"><span class="pre">save_checkpoint</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">experiment_dir</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_best</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">filename</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'checkpoint.pth.tar'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#flame.pytorch.helpers.save_checkpoint" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>state</strong> (<em>dict</em>) – </p></li>
<li><p><strong>experiment_dir</strong> (<em>pathlib.Path</em>) – </p></li>
<li><p><strong>is_best</strong> (<em>bool</em>) – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="flame.pytorch.helpers.rank0">
<code class="sig-prename descclassname"><span class="pre">flame.pytorch.helpers.</span></code><code class="sig-name descname"><span class="pre">rank0</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">func</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#flame.pytorch.helpers.rank0" title="Permalink to this definition">¶</a></dt>
<dd><p>run func only on rank 0</p>
<p>You can use it as a decorator</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@rank0</span>
<span class="k">def</span> <span class="nf">my_print</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>func</strong> (<em>T</em>) – function or lambda</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>T</p>
</dd>
</dl>
</dd></dl>

</div>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="../index.html" title="previous page"><code class="xref py py-mod docutils literal notranslate"><span class="pre">flame.pytorch</span></code></a>
    <a class='right-next' id="next-link" href="amp/index.html" title="next page"><code class="xref py py-mod docutils literal notranslate"><span class="pre">flame.pytorch.helpers.amp</span></code></a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../../../../_static/js/index.1e043a052b0af929e4d8.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2021, SunDoge.<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.5.4.<br/>
    </p>
  </div>
</footer>
  </body>
</html>